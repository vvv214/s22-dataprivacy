### Papers

ML Attacks:

[Reconstructing Training Data with Informed Adversaries](https://arxiv.org/pdf/2201.04845.pdf)
[Spinning Language Models for Propaganda-As-A-Service](https://arxiv.org/pdf/2112.05224.pdf)
[Blind Backdoors in Deep Learning Models](https://arxiv.org/pdf/2005.03823.pdf)
[Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834)
[Enhanced Membership Inference Attacks against Machine Learning Models](https://arxiv.org/pdf/2111.09679.pdf)

Privacy

[Privacy Engineering Meets Software Engineering. On the Challenges of Engineering Privacy By Design](https://arxiv.org/pdf/2007.08613.pdf)
[Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/system/files/sec20summer_fang_prepub.pdf)

Theory
[Numerical Composition of Differential Privacy](https://arxiv.org/pdf/2106.02848.pdf)

DP for ML:
[Scalable Private Learning With PATE](https://arxiv.org/pdf/1802.08908.pdf)

[DPNAS: Neural Architecture Search for Deep Learning with Differential Privacy](https://arxiv.org/pdf/2110.08557.pdf)
[Hyperparameter Tuning with Renyi Differential Privacy](https://arxiv.org/pdf/2110.03620.pdf)
