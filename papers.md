### Papers (under construction)

ML Attacks:

1. [Reconstructing Training Data with Informed Adversaries](https://arxiv.org/pdf/2201.04845.pdf)
1. [Spinning Language Models for Propaganda-As-A-Service](https://arxiv.org/pdf/2112.05224.pdf)
1. [Blind Backdoors in Deep Learning Models](https://arxiv.org/pdf/2005.03823.pdf)
1. [Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834)
1. [Enhanced Membership Inference Attacks against Machine Learning Models](https://arxiv.org/pdf/2111.09679.pdf)
1. [Extracting Training Data from Large Language Models](https://www.usenix.org/system/files/sec21-carlini-extracting.pdf)
1. [Is Private Learning Possible with Instance Encoding?](https://arxiv.org/pdf/2011.05315.pdf)
1. [Submix: Practical Private Prediction For Large-scale Language Models](https://arxiv.org/pdf/2201.00971.pdf)
2. [Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture](https://arxiv.org/pdf/2110.08324.pdf)


Privacy

1. [Privacy Engineering Meets Software Engineering. On the Challenges of Engineering Privacy By Design](https://arxiv.org/pdf/2007.08613.pdf)
1. [Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/system/files/sec20summer_fang_prepub.pdf)
2. [Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning](https://arxiv.org/pdf/2101.04535.pdf)

Theory

1. [Renyi Differential Privacy](https://arxiv.org/pdf/1702.07476.pdf)
1. [Numerical Composition of Differential Privacy](https://arxiv.org/pdf/2106.02848.pdf)

DP for ML:

1. [Scalable Private Learning With PATE](https://arxiv.org/pdf/1802.08908.pdf)
1. 
1. [DPNAS: Neural Architecture Search for Deep Learning with Differential Privacy](https://arxiv.org/pdf/2110.08557.pdf)
1. [Hyperparameter Tuning with Renyi Differential Privacy](https://arxiv.org/pdf/2110.03620.pdf)

DP and Cryptography:

DP and Systems: